{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Principal Component Analysis",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMyk0+7Yzqtg3njkxgD5eRz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratikasarkar/Unsupervised-Learning/blob/master/Principal_Component_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhO16gryq2Z8",
        "colab_type": "text"
      },
      "source": [
        "***Please UpVote if you like the work!!!***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q96dqUZYGDdO",
        "colab_type": "text"
      },
      "source": [
        "# **Principal Component Analysis (PCA)**\n",
        "### It is a data transformation technique. The final objective of PCA is DIMENSIONALITY REDUCTION.\n",
        "The general myth, that the idea of dimensionality reduction means that PCA will drop some of the weak features, is WRONG.\n",
        "\n",
        "Consider we have some features which are highly significant in our data, out of these some are highly correlated to out target variable and some a weakly correlated. There is a chance that those weakly correlated features have high correlation among themselves, eventually adding redundancy and multicolliearity to our models. This multicolliearity effect is the NOISE in PCA. So the intention of PCA is to reduce that noise.\n",
        "\n",
        "***Lets have a look at it into with an example more intuitively.***\n",
        "\n",
        "Consider we have 15 features in a dataset. Out these there are 2 features which are highly correlated to each other.\n",
        "\n",
        "So if we plot a histogram of these 2 features, a majority of the part will be overlapping as they are highly correlated. You can see the plot below :\n",
        "\n",
        "**FIGURE 1 :**   \n",
        "![alt text](https://i.ibb.co/k1TRbNv/Q9GDn.png)\n",
        "\n",
        "The important information which these 2 features will provide us will be those data points which are not redundant/non overlapping and lie at the extreme ends of the histograms as shown in the plot below:\n",
        "\n",
        "**FIGURE 2 :**\n",
        "\n",
        "![alt text](https://i.ibb.co/7VR6ZNy/Q9GDn1.png)\n",
        "\n",
        "This is the information which we cannot afford to lose because the information in these records are responsible for significantly differentiating the 2 features from each other.\n",
        "\n",
        "On the other hand, there is a lot of redundant/overlapping data due to high correlation in these 2 features which gives rise to multicollinearity. The following plot represents this redundant data : \n",
        "\n",
        "**FIGURE 3 :**\n",
        "\n",
        "![alt text](https://i.ibb.co/nnPmXYr/Q9GDn2.png)\n",
        "\n",
        "This redundant data causes multicolliearity. So even if we lose some data from this part, there won't be much information loss.\n",
        "\n",
        "So we can say that we are not sacrificing the feature but we are sacrificing the information content at the low frequency/low variance zone.\n",
        "\n",
        "*Consider an example of predicting a cancerous patient. We can afford to lose some information from a healthy patient(eg. normal bp range/normal rbc-wbc level) as it will not affect our prediction result to an extreme level. But on the other hand we can't affort to lose the information from a cancerous patient(eg. abnormal bp range/abnormal rbc-wbc level), bcoz it could lead to a loss of extensive information and our model could behave unexpectedly.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT0RKRaV7fN1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9aa83d36-8ede-4107-be71-4d3c88d25b47"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2w-un_G1Dq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/gdrive/My Drive/iris.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E18HnYmS1xvu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3e9019f8-454f-419c-ae5b-2a7d6234c7e0"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width species\n",
              "0           5.1          3.5           1.4          0.2  setosa\n",
              "1           4.9          3.0           1.4          0.2  setosa\n",
              "2           4.7          3.2           1.3          0.2  setosa\n",
              "3           4.6          3.1           1.5          0.2  setosa\n",
              "4           5.0          3.6           1.4          0.2  setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHs1tdHs2ny_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = df.drop('species',axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF0ttOzsIUd4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "eea39053-3836-41f7-b874-1f58495e56f1"
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width\n",
              "0           5.1          3.5           1.4          0.2\n",
              "1           4.9          3.0           1.4          0.2\n",
              "2           4.7          3.2           1.3          0.2\n",
              "3           4.6          3.1           1.5          0.2\n",
              "4           5.0          3.6           1.4          0.2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG8bRYuyIWPU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "0aa42128-ea75-4317-b2ad-d1f95966182c"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "ss = StandardScaler()\n",
        "df2_scaled = ss.fit_transform(df2)\n",
        "df2"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal_length  sepal_width  petal_length  petal_width\n",
              "0             5.1          3.5           1.4          0.2\n",
              "1             4.9          3.0           1.4          0.2\n",
              "2             4.7          3.2           1.3          0.2\n",
              "3             4.6          3.1           1.5          0.2\n",
              "4             5.0          3.6           1.4          0.2\n",
              "..            ...          ...           ...          ...\n",
              "145           6.7          3.0           5.2          2.3\n",
              "146           6.3          2.5           5.0          1.9\n",
              "147           6.5          3.0           5.2          2.0\n",
              "148           6.2          3.4           5.4          2.3\n",
              "149           5.9          3.0           5.1          1.8\n",
              "\n",
              "[150 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfnZacYoJRQL",
        "colab_type": "text"
      },
      "source": [
        "np.cov calculates the covariance row-wise. So we transpose the dataset to represent the features as rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idXAWTE9Ij9W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8d5b6efc-c8f4-41c6-e61d-b2fb1a71facc"
      },
      "source": [
        "cov_matrix = np.cov(df2_scaled.T)\n",
        "cov_matrix"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.00671141, -0.11010327,  0.87760486,  0.82344326],\n",
              "       [-0.11010327,  1.00671141, -0.42333835, -0.358937  ],\n",
              "       [ 0.87760486, -0.42333835,  1.00671141,  0.96921855],\n",
              "       [ 0.82344326, -0.358937  ,  0.96921855,  1.00671141]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHuVjNYEJAIE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "4da82a30-30fb-4548-9bf5-a19c04c47e38"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(cov_matrix)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe26c9486a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mweRKhyJ6RB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "0f4e4e60-4e5f-4829-fd23-3ef239a4b9d3"
      },
      "source": [
        "eigen_values,eigen_vectors = np.linalg.eig(cov_matrix)\n",
        "print('Eigen Values\\n',eigen_values)\n",
        "print()\n",
        "print('Eigen Vectors\\n',eigen_vectors)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eigen Values\n",
            " [2.93035378 0.92740362 0.14834223 0.02074601]\n",
            "\n",
            "Eigen Vectors\n",
            " [[ 0.52237162 -0.37231836 -0.72101681  0.26199559]\n",
            " [-0.26335492 -0.92555649  0.24203288 -0.12413481]\n",
            " [ 0.58125401 -0.02109478  0.14089226 -0.80115427]\n",
            " [ 0.56561105 -0.06541577  0.6338014   0.52354627]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owIg0bwURv7-",
        "colab_type": "text"
      },
      "source": [
        "Eigen Vectors here are the principal components(PCs). We need to sort these eigen vectors in descending order w.r.t their corresponding eigen values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhjSx7DGKdU_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a3124588-d51a-453e-8780-8e84ad8ea154"
      },
      "source": [
        "sorted_eig_vals = pd.Series(eigen_values).sort_values(ascending =False)\n",
        "pcs = eigen_vectors[:,list(sorted_eig_vals.index)].T\n",
        "pcs"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.52237162, -0.26335492,  0.58125401,  0.56561105],\n",
              "       [-0.37231836, -0.92555649, -0.02109478, -0.06541577],\n",
              "       [-0.72101681,  0.24203288,  0.14089226,  0.6338014 ],\n",
              "       [ 0.26199559, -0.12413481, -0.80115427,  0.52354627]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g-nmhj-WfMg",
        "colab_type": "text"
      },
      "source": [
        "The actual representation of principal components will be the transpose of eigen vectors as follows:\n",
        "\n",
        "PC1 : [ 0.52237162, -0.26335492,  0.58125401,  0.56561105]\n",
        "\n",
        "PC2 : [-0.37231836, -0.92555649, -0.02109478, -0.06541577]\n",
        "\n",
        "PC3 : [-0.72101681,  0.24203288,  0.14089226,  0.6338014 ]\n",
        "\n",
        "PC4 : [ 0.26199559, -0.12413481, -0.80115427,  0.52354627]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-zFWDQfLf3C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "7fbb720b-0862-4975-883c-1551490b9b4b"
      },
      "source": [
        "tot = np.sum(sorted_eig_vals)\n",
        "var_exp = [(i/tot) * 100 for i in sorted_eig_vals]\n",
        "cum_var_exp = np.cumsum(var_exp)\n",
        "print('Explained variance by each principal component : \\n [PC1,PC2,PC3,PC4]\\n',var_exp)\n",
        "print()\n",
        "print('Cumulative explained variance : ',cum_var_exp)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Explained variance by each principal component : \n",
            " [PC1,PC2,PC3,PC4]\n",
            " [72.77045209380135, 23.03052326768065, 3.683831957627379, 0.5151926808906321]\n",
            "\n",
            "Cumulative explained variance :  [ 72.77045209  95.80097536  99.48480732 100.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWz1vbpZZB1Q",
        "colab_type": "text"
      },
      "source": [
        "So as we can see that most of the variance in data has been explained by the 1st two principal components that is about 96 percent.\n",
        "\n",
        "So most of the information essential to differentiate the feature from each other has been captured by the 1st two PCs.\n",
        "\n",
        "Overdoing PCA is not advisable. Reducing high number of PCs could lead to introducing bias error in our model. The least percentage advisable is around 90 percent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9xVZCj-Yf9d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2a61b383-4cdc-4097-bafe-7ed5b21b1c2f"
      },
      "source": [
        "selected_pcs = pcs[:2]\n",
        "selected_pcs"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.52237162, -0.26335492,  0.58125401,  0.56561105],\n",
              "       [-0.37231836, -0.92555649, -0.02109478, -0.06541577]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRNOFemUlIJF",
        "colab_type": "text"
      },
      "source": [
        "Now to transform our data to a data which has its dimensionality reduced, we need to do a dot product between our originally scaled data and the PCs.\n",
        "\n",
        "This would mean that we are considering using only the important information from the high variance zone(**FIGURE 2**) and eliminating all the redundant noise/less important information by elimininating the PCs which explain the low variance region(FIGURE 3).\n",
        "\n",
        "Our scaled data is 150x4 and our selected PCs are 2X4. So we would need to transpose our selected PCs and to do the dot product."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSl8oxsUlEuB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "be13737a-d830-4ed8-84e3-ec69f25d5eb4"
      },
      "source": [
        "tranps_select_pcs = selected_pcs.T\n",
        "tranps_select_pcs"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.52237162, -0.37231836],\n",
              "       [-0.26335492, -0.92555649],\n",
              "       [ 0.58125401, -0.02109478],\n",
              "       [ 0.56561105, -0.06541577]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHjCf7Rlmfcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba6e1945-5971-4e3c-caa1-4f89a2562b74"
      },
      "source": [
        "projected_data = np.dot(df2_scaled,tranps_select_pcs)\n",
        "projected_data.shape"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9iCrPDwnwn2",
        "colab_type": "text"
      },
      "source": [
        "# Using Kmeans on the transformed data using PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM_rPOzenSFI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6df04e2f-bdd2-47db-b116-154f163da538"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters= 3,n_init=15,random_state=2)\n",
        "kmeans.fit(projected_data)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
              "       n_clusters=3, n_init=15, n_jobs=None, precompute_distances='auto',\n",
              "       random_state=2, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVsCvdpgn9ER",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95c521c7-b9ba-4111-af54-0c480dd2a1a7"
      },
      "source": [
        "kmeans.inertia_"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "116.10924021401527"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSRuugRVoayE",
        "colab_type": "text"
      },
      "source": [
        "# Kmeans on original data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "38c4b540-88b0-4075-ca3b-71fddee20a59",
        "id": "vYie49Rxog8J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters= 3,n_init=15,random_state=2)\n",
        "kmeans.fit(df2_scaled)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
              "       n_clusters=3, n_init=15, n_jobs=None, precompute_distances='auto',\n",
              "       random_state=2, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b01b90d7-0ed3-4113-a202-88f1cc29c979",
        "id": "E8-si2y4og8S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "kmeans.inertia_"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140.96581663074699"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGSEUu3HolDS",
        "colab_type": "text"
      },
      "source": [
        "As we can see that the inertia value on transformed data using PCA is less as compared to the inertia value on the original data. Thus it gives us an improved performance after transforming the data using PCA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkmIcQFNqTy3",
        "colab_type": "text"
      },
      "source": [
        "To know more about why we compare inertia values for comparing models, please do checkout my kernel \"Kmeans Clustering Guide\" : https://www.kaggle.com/pratikasarkar/kmeans-clustering-guide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7r-YokxqxS2",
        "colab_type": "text"
      },
      "source": [
        "***Please UpVote if you like the work!!!***"
      ]
    }
  ]
}